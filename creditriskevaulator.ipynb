{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f78212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f773c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0      10700          7.672            52800        0.431818                5   \n",
       "1       8400          6.692            43600        0.311927                3   \n",
       "2       9000          6.963            46100        0.349241                3   \n",
       "3      10700          7.664            52700        0.430740                5   \n",
       "4      10800          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "lending = pd.read_csv('Resources/lending_data.csv')\n",
    "lending.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a94dc014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63243</th>\n",
       "      <td>8900</td>\n",
       "      <td>6.893</td>\n",
       "      <td>45500</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36991</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.932</td>\n",
       "      <td>45800</td>\n",
       "      <td>0.344978</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>8900</td>\n",
       "      <td>6.896</td>\n",
       "      <td>45500</td>\n",
       "      <td>0.340659</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63047</th>\n",
       "      <td>9000</td>\n",
       "      <td>6.961</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49913</th>\n",
       "      <td>8400</td>\n",
       "      <td>6.712</td>\n",
       "      <td>43800</td>\n",
       "      <td>0.315068</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
       "63243       8900          6.893            45500        0.340659   \n",
       "36991       9000          6.932            45800        0.344978   \n",
       "39985       8900          6.896            45500        0.340659   \n",
       "63047       9000          6.961            46100        0.349241   \n",
       "49913       8400          6.712            43800        0.315068   \n",
       "\n",
       "       num_of_accounts  derogatory_marks  total_debt  \n",
       "63243                3                 0       15500  \n",
       "36991                3                 0       15800  \n",
       "39985                3                 0       15500  \n",
       "63047                3                 0       16100  \n",
       "49913                3                 0       13800  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X=lending.drop('loan_status',axis=1)\n",
    "y=lending['loan_status'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf1c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a StandardScaler model and fit it to the training data\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b0907",
   "metadata": {},
   "source": [
    "# Predicitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce981d",
   "metadata": {},
   "source": [
    "Logistic regression performs better when the noise variables are less than or equal to the explanatory variables. Considering the number of dimensions or columns of data and their particular relevance to credit score, I predict the logistic regression to perform better than random forest classifier. In addition, there are not any categorical dimensions in the data indicating logistic regression would perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f794ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Unscaled Training Data Score: 0.9919177328380795\n",
      "Logistic Regression Unscaled Testing Data Score: 0.9924680148576145\n",
      "Actual:\t\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Predicted:\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(f\"Logistic Regression Unscaled Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Logistic Regression Unscaled Testing Data Score: {classifier.score(X_test, y_test)}\")\n",
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(f'Predicted:\\t{list(classifier.predict(X_test[:10]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d357fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scaled Training Data Score: 0.9941188609162196\n",
      "Logistic Regression Scaled Testing Data Score: 0.9941704498555509\n",
      "Actual:\t\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Predicted:\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "print(f\"Logistic Regression Scaled Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Logistic Regression Scaled Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")\n",
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(f'Predicted:\\t{list(classifier.predict(X_test_scaled[:10]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65af104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18792\n",
      "           1       0.85      0.98      0.91       592\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.99      0.95     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, classifier.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a30155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Unscaled Training Score: 0.9971798046498831\n",
      "Random Forest Unscaled Testing Score: 0.9920037144036319\n",
      "Actual:\t\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Predicted:\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1,n_estimators=50).fit(X_train, y_train)\n",
    "print(f'Random Forest Unscaled Training Score: {clf.score(X_train, y_train)}')\n",
    "print(f'Random Forest Unscaled Testing Score: {clf.score(X_test, y_test)}')\n",
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(f'Predicted:\\t{list(clf.predict(X_test[:10]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6759582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Scaled Training Score: 0.9971798046498831\n",
      "Random Forest Scaled Testing Score: 0.9917457697069748\n",
      "Actual:\t\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Predicted:\t[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=1,n_estimators=50).fit(X_train_scaled, y_train)\n",
    "print(f'Random Forest Scaled Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Random Forest Scaled Testing Score: {clf.score(X_test_scaled, y_test)}')\n",
    "print(f'Actual:\\t\\t{list(y_test[:10])}')\n",
    "print(f'Predicted:\\t{list(clf.predict(X_test_scaled[:10]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cca5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     18792\n",
      "           1       0.85      0.89      0.87       592\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.92      0.94      0.93     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1926de",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fc9c8",
   "metadata": {},
   "source": [
    "The logistic regression testing data score is to some degree higher than the random forest classifier data test score. Both models do comparably well, almost identical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
